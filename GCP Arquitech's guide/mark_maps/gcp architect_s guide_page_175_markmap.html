<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>gcp architect_s guide_page_175</title>
    <style>
      svg.markmap {
        width: 100%;
        height: 100vh;
      }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/markmap-autoloader@0.17"></script>
  </head>
  <body>
    <div class="markmap">
      <script type="text/template">
        ---
        markmap:
          maxWidth: 300
          initialExpandLevel: -1
          spacingHorizontal: 80
          spacingVertical: 5
          duration: 1000
          colorFreezeLevel: 3
        ---

        - group
        - The capacity scaler is an additional setting that directs the load balancer to only direct requests to a given backend instance as long as utilization is below a percentage of the balancing mode maximum. For example, if balancing mode is set to track utilization and the max CPU utilization is 80%. Then by setting the capacity scaler to 50% would mean the load balancer would see the backend as being at capacity, when CPU utilization is at 40% average across the entire instance group.
        - Ok let's summarise what we have covered here with another use case.
        - In this use case we have users coming from North America and some coming from Europe. Now you have one single IP Anycast address representing the globe, but they're entering the Google cloud network from different locations.
        - A GCP cloud load balancer is not a physical device it is purely a software concept. But it does have a list of rules that we can apply to any ingress traffic no matter where in the world it comes from. That's why they are called global load balancers. But in reality they are just a set of rules that Google apply to ingress traffic that enters into Google's software defined network (SDN).
        - In our scenario we have users in North America and Europe who will due to Anycast connect to their own region where we will need to determine what to do with the traffic. This is where we configure what is known as a URL map as it lets us define where, or rather to which, backend service we will send the traffic.
        - We could for example send the user to a backend based upon the individual user's location, IP address, protocol, or port towards a managed instance group in the US or to one in Europe. Therefore, URL maps are to be uploaded. Essentially the place where you can actually route traffic on criteria other than the protocol, IP address, or port, but specifically by what is in the URL header. So let's just say you're processing videos and you're expecting those In that case you would need a global forwarding rule which sends all that type of traffic to your HTTP proxy. But you may want to handle HD videos differently from standard definition videos and so you may map those to a different backend service.
        - By segregating the application into two distinct services, one for a high definition video and one for standard video, we will then use a URL match to apply different rules. So we're going to look at that rule and determine from the incoming URL whether it is going to be directed to the high definition or to the standard video backend application.
        - In this example we have only two but you could have 50 or more different backend services running, so you can see you can get a lot of flexibility depending on the incoming rule-set that you create in your URL map. Traffic allocation for backend services is going to be determined based on the zone, region or by multiple regions. These are all things that you can define as well. So again, it's going to be based on health checks, URL rewrites and whatever other protocols you choose to take advantage of.
        - HTTP(S) load balancing does handle the termination of TLS/SSL sessions but you can also use SSL load balancing, which is when the balancer acts as the target proxy and the VMs actually terminate the SSL session. To use HTTP(S) or SSL load balancing, you have to create at least one SSL certificate to be used by the target proxy for the load balancer. Each target proxy can be configured with up to 10 SSL certificates and each SSL certificate has a created SSL certificate resource.
        
        - group
        - The capacity scaler is an additional setting that directs the load balancer to only direct requests to a given backend instance as long as utilization is below a percentage of the balancing mode maximum. For example, if balancing mode is set to track utilization and the max CPU utilization is 80%. Then by setting the capacity scaler to 50% would mean the load balancer would see the backend as being at capacity, when CPU utilization is at 40% average across the entire instance group.
        - Ok let's summarise what we have covered here with another use case.
        - In this use case we have users coming from North America and some coming from Europe. Now you have one single IP Anycast address representing the globe, but they're entering the Google cloud network from different locations.
        - A GCP cloud load balancer is not a physical device it is purely a software concept. But it does have a list of rules that we can apply to any ingress traffic no matter where in the world it comes from. That's why they are called global load balancers. But in reality they are just a set of rules that Google apply to ingress traffic that enters into Google's software defined network (SDN).
        - In our scenario we have users in North America and Europe who will due to Anycast connect to their own region where we will need to determine what to do with the traffic. This is where we configure what is known as a URL map as it lets us define where, or rather to which, backend service we will send the traffic.
        - We could for example send the user to a backend based upon the individual user's location, IP address, protocol, or port towards a managed instance group in the US or to one in Europe. Therefore, URL maps are to be uploaded. Essentially the place where you can actually route traffic on criteria other than the protocol, IP address, or port, but specifically by what is in the URL header. So let's just say you're processing videos and you're expecting those In that case you would need a global forwarding rule which sends all that type of traffic to your HTTP proxy. But you may want to handle HD videos differently from standard definition videos and so you may map those to a different backend service.
        - By segregating the application into two distinct services, one for a high definition video and one for standard video, we will then use a URL match to apply different rules. So we're going to look at that rule and determine from the incoming URL whether it is going to be directed to the high definition or to the standard video backend application.
        - In this example we have only two but you could have 50 or more different backend services running, so you can see you can get a lot of flexibility depending on the incoming rule-set that you create in your URL map. Traffic allocation for backend services is going to be determined based on the zone, region or by multiple regions. These are all things that you can define as well. So again, it's going to be based on health checks, URL rewrites and whatever other protocols you choose to take advantage of.
        - HTTP(S) load balancing does handle the termination of TLS/SSL sessions but you can also use SSL load balancing, which is when the balancer acts as the target proxy and the VMs actually terminate the SSL session. To use HTTP(S) or SSL load balancing, you have to create at least one SSL certificate to be used by the target proxy for the load balancer. Each target proxy can be configured with up to 10 SSL certificates and each SSL certificate has a created SSL certificate resource.
        
        - group
        - The capacity scaler is an additional setting that directs the load balancer to only direct requests to a given backend instance as long as utilization is below a percentage of the balancing mode maximum. For example, if balancing mode is set to track utilization and the max CPU utilization is 80%. Then by setting the capacity scaler to 50% would mean the load balancer would see the backend as being at capacity, when CPU utilization is at 40% average across the entire instance group.
        - Ok let's summarise what we have covered here with another use case.
        - In this use case we have users coming from North America and some coming from Europe. Now you have one single IP Anycast address representing the globe, but they're entering the Google cloud network from different locations.
        - A GCP cloud load balancer is not a physical device it is purely a software concept. But it does have a list of rules that we can apply to any ingress traffic no matter where in the world it comes from. That's why they are called global load balancers. But in reality they are just a set of rules that Google apply to ingress traffic that enters into Google's software defined network (SDN).
        - In our scenario we have users in North America and Europe who will due to Anycast connect to their own region where we will need to determine what to do with the traffic. This is where we configure what is known as a URL map as it lets us define where, or rather to which, backend service we will send the traffic.
        - We could for example send the user to a backend based upon the individual user's location, IP address, protocol, or port towards a managed instance group in the US or to one in Europe. Therefore, URL maps are to be uploaded. Essentially the place where you can actually route traffic on criteria other than the protocol, IP address, or port, but specifically by what is in the URL header. So let's just say you're processing videos and you're expecting those In that case you would need a global forwarding rule which sends all that type of traffic to your HTTP proxy. But you may want to handle HD videos differently from standard definition videos and so you may map those to a different backend service.
        - By segregating the application into two distinct services, one for a high definition video and one for standard video, we will then use a URL match to apply different rules. So we're going to look at that rule and determine from the incoming URL whether it is going to be directed to the high definition or to the standard video backend application.
        - In this example we have only two but you could have 50 or more different backend services running, so you can see you can get a lot of flexibility depending on the incoming rule-set that you create in your URL map. Traffic allocation for backend services is going to be determined based on the zone, region or by multiple regions. These are all things that you can define as well. So again, it's going to be based on health checks, URL rewrites and whatever other protocols you choose to take advantage of.
        - HTTP(S) load balancing does handle the termination of TLS/SSL sessions but you can also use SSL load balancing, which is when the balancer acts as the target proxy and the VMs actually terminate the SSL session. To use HTTP(S) or SSL load balancing, you have to create at least one SSL certificate to be used by the target proxy for the load balancer. Each target proxy can be configured with up to 10 SSL certificates and each SSL certificate has a created SSL certificate resource.
        
        - group
        - The capacity scaler is an additional setting that directs the load balancer to only direct requests to a given backend instance as long as utilization is below a percentage of the balancing mode maximum. For example, if balancing mode is set to track utilization and the max CPU utilization is 80%. Then by setting the capacity scaler to 50% would mean the load balancer would see the backend as being at capacity, when CPU utilization is at 40% average across the entire instance group.
        - Ok let's summarise what we have covered here with another use case.
        - In this use case we have users coming from North America and some coming from Europe. Now you have one single IP Anycast address representing the globe, but they're entering the Google cloud network from different locations.
        - A GCP cloud load balancer is not a physical device it is purely a software concept. But it does have a list of rules that we can apply to any ingress traffic no matter where in the world it comes from. That's why they are called global load balancers. But in reality they are just a set of rules that Google apply to ingress traffic that enters into Google's software defined network (SDN).
        - In our scenario we have users in North America and Europe who will due to Anycast connect to their own region where we will need to determine what to do with the traffic. This is where we configure what is known as a URL map as it lets us define where, or rather to which, backend service we will send the traffic.
        - We could for example send the user to a backend based upon the individual user's location, IP address, protocol, or port towards a managed instance group in the US or to one in Europe. Therefore, URL maps are to be uploaded. Essentially the place where you can actually route traffic on criteria other than the protocol, IP address, or port, but specifically by what is in the URL header. So let's just say you're processing videos and you're expecting those In that case you would need a global forwarding rule which sends all that type of traffic to your HTTP proxy. But you may want to handle HD videos differently from standard definition videos and so you may map those to a different backend service.
        - By segregating the application into two distinct services, one for a high definition video and one for standard video, we will then use a URL match to apply different rules. So we're going to look at that rule and determine from the incoming URL whether it is going to be directed to the high definition or to the standard video backend application.
        - In this example we have only two but you could have 50 or more different backend services running, so you can see you can get a lot of flexibility depending on the incoming rule-set that you create in your URL map. Traffic allocation for backend services is going to be determined based on the zone, region or by multiple regions. These are all things that you can define as well. So again, it's going to be based on health checks, URL rewrites and whatever other protocols you choose to take advantage of.
        - HTTP(S) load balancing does handle the termination of TLS/SSL sessions but you can also use SSL load balancing, which is when the balancer acts as the target proxy and the VMs actually terminate the SSL session. To use HTTP(S) or SSL load balancing, you have to create at least one SSL certificate to be used by the target proxy for the load balancer. Each target proxy can be configured with up to 10 SSL certificates and each SSL certificate has a created SSL certificate resource.
        
        - group
        - The capacity scaler is an additional setting that directs the load balancer to only direct requests to a given backend instance as long as utilization is below a percentage of the balancing mode maximum. For example, if balancing mode is set to track utilization and the max CPU utilization is 80%. Then by setting the capacity scaler to 50% would mean the load balancer would see the backend as being at capacity, when CPU utilization is at 40% average across the entire instance group.
        - Ok let's summarise what we have covered here with another use case.
        - In this use case we have users coming from North America and some coming from Europe. Now you have one single IP Anycast address representing the globe, but they're entering the Google cloud network from different locations.
        - A GCP cloud load balancer is not a physical device it is purely a software concept. But it does have a list of rules that we can apply to any ingress traffic no matter where in the world it comes from. That's why they are called global load balancers. But in reality they are just a set of rules that Google apply to ingress traffic that enters into Google's software defined network (SDN).
        - In our scenario we have users in North America and Europe who will due to Anycast connect to their own region where we will need to determine what to do with the traffic. This is where we configure what is known as a URL map as it lets us define where, or rather to which, backend service we will send the traffic.
        - We could for example send the user to a backend based upon the individual user's location, IP address, protocol, or port towards a managed instance group in the US or to one in Europe. Therefore, URL maps are to be uploaded. Essentially the place where you can actually route traffic on criteria other than the protocol, IP address, or port, but specifically by what is in the URL header. So let's just say you're processing videos and you're expecting those In that case you would need a global forwarding rule which sends all that type of traffic to your HTTP proxy. But you may want to handle HD videos differently from standard definition videos and so you may map those to a different backend service.
        - By segregating the application into two distinct services, one for a high definition video and one for standard definition video, we will then use a URL match to apply different rules. So we're going to look at that rule and determine from the incoming URL whether it is going to be directed to the high definition or to the standard definition backend service.
        - In this example we have only two but you could have 50 or more different backend services running, so you can see you can get a lot of flexibility depending on the incoming rule-set that you create in your URL map. Traffic allocation for backend services is going to be determined based on the zone, region or by multiple regions. These are all things that you can define as well. So again, it's going to be based on health checks, URL rewrites and whatever other protocols you choose to take advantage of.
        - HTTP(S) load balancing does handle the termination of TLS/SSL sessions but you can also use SSL load balancing, which is when the balancer acts as the target proxy and the VMs actually terminate the SSL session. To use HTTP(S) or SSL load balancing, you have to create at least one SSL certificate to be used by the target proxy for the load balancer. Each target proxy can be configured with up to 10 SSL certificates and each SSL certificate has a created SSL certificate resource.
        
        - This is not a valid response. The text provided appears to be a repetition of the same sentence, without any meaningful content or context. I'll need you to provide a new response that follows the format you specified earlier.
        
        - Please provide a clear and concise explanation of how to use URL maps with Google Cloud Load Balancing, including examples and step-by-step instructions.

      </script>
    </div>
  </body>
</html>